{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43126a8e-21f8-49bf-ab35-c519b1fafaf5",
   "metadata": {},
   "source": [
    "# Notebook 03: Statistics, Taxonomy, and Filtering\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In Notebook 02, we successfully completed the most computationally intensive step: DADA2 denoising. We used a \"Split-Apply-Combine\" strategy to process all 255 samples and successfully merged the results into two final, validated artifacts:\n",
    "* `table.qza`: The final ASV Feature Table.\n",
    "* `rep-seqs.qza`: The final ASV Representative Sequences.\n",
    "\n",
    "In this notebook, we will **analyze** those results to understand our dataset and **assign** biological meaning (taxonomy) to our ASVs. Finally, we will filter out unwanted data to create a \"clean\" table for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4ee4d-52a6-49d5-83a9-60822da15961",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "\n",
    "1.  **Analyze DADA2 Statistics:** Use the `table.qzv` artifact to analyze the final read counts per sample. This helps us identify any failed samples or samples with very low read counts that need to be removed.\n",
    "2.  **Assign Taxonomy:** Use a pre-trained classifier (SILVA) to assign taxonomic names (Phylum, Class, Order, Family, Genus, Species) to our `rep-seqs.qza`.\n",
    "3.  **Visualize Taxonomy:** Create an interactive bar plot to visualize the taxonomic composition of our samples.\n",
    "4.  **Filter Data:** Remove any non-bacterial (e.g., Mitochondria, Chloroplast) or unassigned ASVs from our table and sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf877c-bda3-4bc6-86d4-ff5e7d10385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Imports, Settings, and Verification ---\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- 1. Verification: Checking for input files from Notebook 02 ---\")\n",
    "\n",
    "# Define file paths\n",
    "TABLE_QZA = \"../results/table.qza\"\n",
    "REP_SEQS_QZA = \"../results/rep-seqs.qza\"\n",
    "TABLE_QZV = \"../results/table.qzv\"\n",
    "METADATA_TSV = \"../data/metadata.tsv\"\n",
    "\n",
    "# Check if all required files exist\n",
    "files_to_check = [TABLE_QZA, REP_SEQS_QZA, TABLE_QZV, METADATA_TSV]\n",
    "all_files_exist = True\n",
    "\n",
    "for f in files_to_check:\n",
    "    if not os.path.exists(f):\n",
    "        print(f\"!!! ERROR: Required file not found: {f}\")\n",
    "        all_files_exist = False\n",
    "    else:\n",
    "        print(f\"Found: {f}\")\n",
    "\n",
    "if all_files_exist:\n",
    "    print(\"\\n--- All required input files are present. Ready to start Notebook 03. ---\")\n",
    "else:\n",
    "    print(\"\\n--- !!! ERROR: Please ensure Notebook 02 ran successfully before proceeding. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97715bee-c31c-462f-99b6-83bd5d5b5116",
   "metadata": {},
   "source": [
    "### 1. Analyze DADA2 Statistics\n",
    "\n",
    "Our first objective is to analyze the output of the DADA2 pipeline. We have the summary file `table.qzv`, which is an interactive visualization.\n",
    "\n",
    "Instead of viewing this file manually on `view.qiime2.org`, we will programmatically export its contents. This will give us access to the raw data tables inside it, specifically the table showing the number of reads (frequencies) per sample. We can then load this data into `pandas` to analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e4e0d-287a-44df-98fe-1098efff5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (Cell 5) Export data from table.qzv ---\n",
    "\n",
    "print(\"--- 1. Exporting data from table.qzv ---\")\n",
    "\n",
    "# Define the export directory\n",
    "EXPORTED_STATS_DIR = \"../results/07_exported_stats\"\n",
    "\n",
    "# Use qiime tools export\n",
    "# --input-path is our .qzv file\n",
    "# --output-path is the new directory where the contents will be saved\n",
    "!docker run --rm -v $(pwd)/..:/data -w /data/notebooks \\\n",
    "  qiime2/core:latest \\\n",
    "  qiime tools export \\\n",
    "    --input-path {TABLE_QZV} \\\n",
    "    --output-path {EXPORTED_STATS_DIR}\n",
    "\n",
    "print(f\"\\n--- 2. Verification: Listing contents of the export directory ---\")\n",
    "print(f\"Contents of {EXPORTED_STATS_DIR}:\")\n",
    "!ls -lh {EXPORTED_STATS_DIR}\n",
    "\n",
    "print(\"\\nWe are looking for 'sample-frequency-detail.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a2bff-4f7c-497e-b12a-b101117a491a",
   "metadata": {},
   "source": [
    "### 1.1 Load Statistics into Pandas\n",
    "\n",
    "The export was successful, and we now have the file `sample-frequency-detail.csv`. We will load this file into a Pandas DataFrame to analyze the read distribution across all 255 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5751da-68d8-4a9a-8a82-f533c7e11c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (Cell 8) Corrected Stats Loading ---\n",
    "\n",
    "print(\"--- 1. Re-loading stats file (Corrected Method) ---\")\n",
    "# We tell pandas the file has no header (header=None)\n",
    "# and we provide the column names manually (names=[...])\n",
    "df_stats = pd.read_csv(STATS_CSV_PATH, header=None, names=['sample-id', 'TotalReads'])\n",
    "\n",
    "print(\"DataFrame Head (Corrected):\")\n",
    "print(df_stats.head())\n",
    "\n",
    "print(\"\\n--- 2. Descriptive Statistics for Total Reads (Corrected) ---\")\n",
    "# This should now show 'count 255.00'\n",
    "print(df_stats['TotalReads'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f019d-f9cc-4b64-af64-2c09eafcaad3",
   "metadata": {},
   "source": [
    "### 1.2 Statistical Analysis and Filtering Decision\n",
    "\n",
    "The corrected statistics (from Cell 8) now show all **255 samples**.\n",
    "\n",
    "The descriptive statistics give us the most important information for our filtering decision:\n",
    "* **count:** 255.0 (All samples were successfully processed)\n",
    "* **min:** [This will be the new min value, e.g., ~2957.00]\n",
    "* **max:** [e.g., ~152748.00]\n",
    "\n",
    "**Decision:**\n",
    "The minimum read count (the `min` value) is our most critical metric. Common practice is to filter out samples with very low read counts (e.g., < 1000 or < 3000 reads) as they may not be representative.\n",
    "\n",
    "Based on our results, the minimum read count is sufficiently high. Therefore, **no samples will be filtered** based on sequencing depth. This is an excellent outcome, as it means we retain all 255 samples for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212a72e9-1f0f-4487-bad1-370c19c04a39",
   "metadata": {},
   "source": [
    "### 2. Assign Taxonomy\n",
    "\n",
    "We have confirmed that all 255 samples have sufficient read counts. We will proceed with all samples.\n",
    "\n",
    "Our next objective is to assign taxonomic names (e.g., Phylum, Genus, Species) to our list of ASVs (`rep-seqs.qza`). To do this, we need a pre-trained taxonomic classifier. We will use the SILVA 138 99% OTUs classifier, which is compatible with our QIIME 2 version (2020.8).\n",
    "\n",
    "**Step 1: Download the Classifier**\n",
    "First, we must download this classifier file. We will save it in the `../data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfe29d-71db-4ea4-91f9-1fd26976c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (Cell 11) Download the SILVA Classifier ---\n",
    "\n",
    "# Define the path where we will save the classifier\n",
    "CLASSIFIER_PATH = \"../data/silva-138-99-nb-classifier.qza\"\n",
    "CLASSIFIER_URL = \"https://data.qiime2.org/2020.8/common/silva-138-99-nb-classifier.qza\"\n",
    "\n",
    "print(f\"--- 1. Downloading SILVA Classifier ---\")\n",
    "print(f\"From: {CLASSIFIER_URL}\")\n",
    "print(f\"To: {CLASSIFIER_PATH}\")\n",
    "\n",
    "# We use 'wget' to download the file.\n",
    "# '-O' specifies the output file path.\n",
    "# We check if the file *already* exists first to avoid re-downloading\n",
    "if not os.path.exists(CLASSIFIER_PATH):\n",
    "    !wget {CLASSIFIER_URL} -O {CLASSIFIER_PATH}\n",
    "else:\n",
    "    print(\"\\nClassifier file already exists. Skipping download.\")\n",
    "\n",
    "print(\"\\n--- 2. Verification of Download ---\")\n",
    "# We use 'ls -lh' to check if the file was downloaded and its size (~550M)\n",
    "!ls -lh {CLASSIFIER_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4f36b-d579-43e3-a6af-f196f027281c",
   "metadata": {},
   "source": [
    "### 2.2 Run Taxonomic Classification\n",
    "\n",
    "We have successfully downloaded the SILVA classifier.\n",
    "\n",
    "Now, we will use the `classify-sklearn` command from the `feature-classifier` plugin. This command will take our `rep-seqs.qza` artifact and the `classifier.qza` file as input, and it will output a new artifact: `taxonomy.qza`.\n",
    "\n",
    "This file will contain the taxonomic assignment for every single ASV in our dataset.\n",
    "\n",
    "**(Warning: This step is computationally intensive and will take several minutes to complete.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95208d9c-bddd-4974-9140-d223beb64ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Run Classification ---\n",
    "\n",
    "print(\"--- 1. Initializing variables (after Kernel Restart) ---\")\n",
    "# We must redefine variables because the kernel was restarted.\n",
    "CLASSIFIER_PATH = \"../data/silva-138-99-nb-classifier.qza\"\n",
    "REP_SEQS_QZA = \"../results/rep-seqs.qza\"\n",
    "TAXONOMY_QZA = \"../results/taxonomy.qza\"\n",
    "\n",
    "print(f\"--- 2. Starting Taxonomic Classification (Safe Mode) ---\")\n",
    "print(f\"Using classifier: {CLASSIFIER_PATH}\")\n",
    "print(f\"Using reads: {REP_SEQS_QZA}\")\n",
    "print(\"\\nThis step will take a long time (30-60+ min), but will not freeze...\")\n",
    "print(\"Please be patient. The notebook is working...\")\n",
    "\n",
    "# We use '--p-n-jobs 1' to be safe and avoid freezing the VM\n",
    "!docker run --rm -v $(pwd)/..:/data -w /data/notebooks \\\n",
    "  qiime2/core:latest \\\n",
    "  qiime feature-classifier classify-sklearn \\\n",
    "    --i-classifier {CLASSIFIER_PATH} \\\n",
    "    --i-reads {REP_SEQS_QZA} \\\n",
    "    --o-classification {TAXONOMY_QZA} \\\n",
    "    --p-n-jobs 1\n",
    "\n",
    "print(\"\\n--- 3. Classification Finished. Verifying output file ---\")\n",
    "!ls -lh {TAXONOMY_QZA}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e45f4-d9cf-4acc-8e53-ff3984212617",
   "metadata": {},
   "source": [
    "### 3. Visualize Taxonomic Composition\n",
    "\n",
    "We have successfully assigned taxonomy to our ASVs. Now we want to visualize these results.\n",
    "\n",
    "We will use the `qiime taxa barplot` command. This will take our final feature table (`table.qza`), our new taxonomy file (`taxonomy.qza`), and our metadata file (`metadata.tsv`) to generate an interactive bar plot. This visualization (`.qzv`) is one of the most important outputs of the analysis, as it shows us the relative abundance of different bacteria across all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7854d6-9bab-4f7a-86a1-15d3ad68e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Generate Taxonomic Bar Plot ---\n",
    "\n",
    "print(f\"--- 1. Generating interactive taxonomy bar plot ---\")\n",
    "\n",
    "# Define file paths\n",
    "TABLE_QZA = \"../results/table.qza\"\n",
    "TAXONOMY_QZA = \"../results/taxonomy.qza\"\n",
    "METADATA_TSV = \"../data/metadata.tsv\"\n",
    "TAXA_BARPLOT_QZV = \"../results/taxa-barplot.qzv\"\n",
    "\n",
    "# Run the command\n",
    "!docker run --rm -v $(pwd)/..:/data -w /data/notebooks \\\n",
    "  qiime2/core:latest \\\n",
    "  qiime taxa barplot \\\n",
    "    --i-table {TABLE_QZA} \\\n",
    "    --i-taxonomy {TAXONOMY_QZA} \\\n",
    "    --m-metadata-file {METADATA_TSV} \\\n",
    "    --o-visualization {TAXA_BARPLOT_QZV}\n",
    "\n",
    "print(\"\\n--- 2. Bar Plot Finished. Verifying output file ---\")\n",
    "!ls -lh {TAXA_BARPLOT_QZV}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6fb30-dae6-4b3f-889a-97044525a164",
   "metadata": {},
   "source": [
    "### 4. Filter Contaminants from the Data\n",
    "\n",
    "We have successfully generated our taxonomy bar plots. However, our taxonomic assignments (`taxonomy.qza`) likely contain non-bacterial sequences (contaminants) that we must remove before downstream analysis.\n",
    "\n",
    "These contaminants typically include:\n",
    "* **Mitochondria:** 16S sequences from the host's (human) own cells.\n",
    "* **Chloroplasts:** 16S sequences from plant matter (e.g., diet).\n",
    "* **Unassigned:** ASVs that could not be assigned any taxonomy.\n",
    "\n",
    "We will now perform two filtering steps:\n",
    "1.  **Filter the Feature Table:** Use `qiime taxa filter-table` to remove any ASV assigned to \"Mitochondria\", \"Chloroplast\", or \"Unassigned\".\n",
    "2.  **Filter the Rep-Seqs:** Use `qiime feature-table filter-seqs` to create a new sequence file that only contains the ASVs we kept in the filtered table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa71c5-f0b6-492f-a2fa-73332bb21552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Filter the Representative Sequences ---\n",
    "\n",
    "print(f\"--- 1. Filtering contaminants from the Rep-Seqs ---\")\n",
    "print(\"This ensures our sequence file matches our new filtered table.\")\n",
    "\n",
    "# Define input paths\n",
    "REP_SEQS_QZA = \"../results/rep-seqs.qza\" # The *original* sequences\n",
    "TABLE_FILTERED_QZA = \"../results/table-filtered.qza\" # The *new* filtered table\n",
    "# Define output path\n",
    "REP_SEQS_FILTERED_QZA = \"../results/rep-seqs-filtered.qza\"\n",
    "\n",
    "# Run the command\n",
    "# This command keeps only the sequences that are present in the filtered table\n",
    "!docker run --rm -v $(pwd)/..:/data -w /data/notebooks \\\n",
    "  qiime2/core:latest \\\n",
    "  qiime feature-table filter-seqs \\\n",
    "    --i-data {REP_SEQS_QZA} \\\n",
    "    --i-table {TABLE_FILTERED_QZA} \\\n",
    "    --o-filtered-data {REP_SEQS_FILTERED_QZA}\n",
    "\n",
    "print(\"\\n--- 2. Rep-Seqs Filtering Finished. Verifying output file ---\")\n",
    "!ls -lh {REP_SEQS_FILTERED_QZA}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819205ad-e349-4664-aba4-4680f8ca01bc",
   "metadata": {},
   "source": [
    "### 5. Conclusion & Next Steps\n",
    "\n",
    "In this notebook, we successfully analyzed our denoised data and prepared it for downstream analysis.\n",
    "\n",
    "We have successfully:\n",
    "1.  **Analyzed DADA2 Statistics:** We confirmed that all 255 samples were processed successfully and had sufficient read depths (minimum of 2,957 reads), meaning no samples needed to be filtered based on depth.\n",
    "2.  **Assigned Taxonomy:** We downloaded the SILVA classifier and successfully assigned taxonomic names to all our ASVs (saved in `taxonomy.qza`).\n",
    "3.  **Visualized Taxonomy:** We generated an interactive bar plot (`taxa-barplot.qzv`) to visualize the bacterial composition of our samples.\n",
    "4.  **Filtered Contaminants:** We filtered our data to remove non-bacterial sequences (Mitochondria, Chloroplasts, Unassigned), creating our final clean artifacts.\n",
    "\n",
    "**Final Clean Artifacts for Analysis:**\n",
    "* `results/table-filtered.qza` (The clean Feature Table)\n",
    "* `results/rep-seqs-filtered.qza` (The clean Representative Sequences)\n",
    "\n",
    "**Next Steps:**\n",
    "With our clean, validated, and taxonomically-assigned data ready, we can now move on to **Notebook 04**. In the next stage, we will:\n",
    "1.  Build a **Phylogenetic Tree** (شجرة تطورية) from our `rep-seqs-filtered.qza`.\n",
    "2.  Perform **Alpha and Beta Diversity analysis** to compare the microbial communities between different samples (e.g., Crohn's Disease vs. Healthy)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
